[project]
name = "llama3-abdm"
version = "0.1.0"
description = ""
authors = [
    {name = "MountAye", email = "dev@mountaye.com"}
]
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "llama-stack (>=0.1.4,<0.2.0)",
    "opencc (>=1.1.9,<2.0.0)",
    "torch (>=2.6.0,<3.0.0)",
    "torchvision (>=0.21.0,<0.22.0)",
    "torchaudio (>=2.6.0,<3.0.0)",
    "huggingface-hub (>=0.29.2,<0.30.0)",
    "transformers (>=4.49.0,<5.0.0)",
    "datasets (>=3.3.2,<4.0.0)",
    "accelerate (>=1.4.0,<2.0.0)",
    "jupyter (>=1.1.1,<2.0.0)",
    "packaging (>=24.2,<25.0)",
    "ninja (>=1.11.1.3,<2.0.0.0)",
    "peft (>=0.14.0,<0.15.0)"
]

[tool.poetry]
packages = [{include = "llama3_abdm", from = "src"}]

[[tool.poetry.source]]
name = "torch-cu126"
url = "https://download.pytorch.org/whl/cu126"
priority = "explicit"

[tool.poetry.dependencies]
torch = {source = "torch-cu126"}
torchvision = {source = "torch-cu126"}
torchaudio = {source = "torch-cu126"}
[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"
